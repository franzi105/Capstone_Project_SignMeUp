{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply MediaPipe on video files/save video with landmarks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies MediaPipe Hollistic on a given video file. It detects face, pose and hand landmarks. These landmarks are tracked over time and added to the video file. \n",
    "The video with landmarks added is saved as mp4 file at the end of the notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # drawing utilities\n",
    "\n",
    "# function to detect MP Holistic landmarks from an image, e.g. frames of your camera feed\n",
    "def mediapipe_detection(image, model): \n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # color conversion BGR to RGB\n",
    "    image.flags.writeable = False                   # image no longer writeable\n",
    "    results = model.process(image)                  # make prediction\n",
    "    image.flags.writeable = True                    # image is writeable again\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # color conversion back to original\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to draw landmarks points and connecting lines on top of an image, e.g. on top of your camera feed\n",
    "def draw_styled_landmarks(image, results): \n",
    "    # draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                              mp_drawing.DrawingSpec(color=(80,22,10), thickness=1, circle_radius=2), \n",
    "                              mp_drawing.DrawingSpec(color=(224,208,64), thickness=2, circle_radius=2))\n",
    "    #draw pose connections\n",
    "    #mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "    #                          mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "    #                          mp_drawing.DrawingSpec(color=(224,208,64), thickness=2, circle_radius=2)) \n",
    "    #draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0), thickness=4, circle_radius=3), \n",
    "                              mp_drawing.DrawingSpec(color=(255,0,255), thickness=6, circle_radius=2))\n",
    "    # draw right hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0), thickness=4, circle_radius=3), \n",
    "                              mp_drawing.DrawingSpec(color=(255,0,255), thickness=6, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining input directory\n",
    "INPUT = '../data/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and processing of video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture(f'{INPUT}20230428_112427.mp4')\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "#video will be saved as mp4 file\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, 25.0, (frame_width,frame_height))\n",
    "\n",
    "# Read until video is completed\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic: \n",
    "  while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "      # Display the resulting frame\n",
    "      # make detections \n",
    "      image, results = mediapipe_detection(frame, holistic)\n",
    "      #draw_landmarks(image, results)\n",
    "      draw_styled_landmarks(image, results)\n",
    "      out.write(frame)\n",
    "      cv2.imshow('Frame',frame)\n",
    "      # Press Q on keyboard to  exit\n",
    "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # Break the loop\n",
    "    else: \n",
    "      break\n",
    "    \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1) # some workaround to fix the bug, that window doesn't close\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
