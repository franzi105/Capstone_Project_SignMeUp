{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow - Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/roberthatch/gislr-feature-data-on-the-shoulders/notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the original notebook from one kaggle user.\n",
    "\n",
    "\n",
    "this notebook generates a preprocessing layer that transforms the whole dataset into numpy arrays.\n",
    "Some landmarks are merged and sequences are cut in 3 time blocks and averaged.\n",
    "\n",
    "\n",
    "\n",
    "If I understand it correctly, the flow is as follow:\n",
    "\n",
    "1. Convert x_ into x containing avg face, avg pose, lips, left hand, right hand for every frame, e.g. [23, 84, 3]\n",
    "2. Pad x such that first dim is divisible by 3: [23, 84, 3] -> [24, 84, 3]\n",
    "3. Split padded x into three parts, and for each part, compute mean and std over frames, concat and flatten: [8, 84, 3] -> [2, 84, 3] -> [1, 504]\n",
    "4. Add flattened mean and std of x to features list, which now contains means and stds of the three parts + overall mean and std\n",
    "5. Resize x to [15, 84, 3], flatten and append it to features list\n",
    "\n",
    "* final shape of data: x (94477, 5796) and y (94477,)\n",
    "* takes ca 15 minutes to compile whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "import os\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit dataset for quick test\n",
    "QUICK_TEST = True\n",
    "QUICK_LIMIT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Kaggle\n",
    "# LANDMARK_FILES_DIR = \"/kaggle/input/asl-signs/train_landmark_files\"\n",
    "# TRAIN_FILE = \"/kaggle/input/asl-signs/train.csv\"\n",
    "# label_map = json.load(open(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\", \"r\"))\n",
    "\n",
    "#for local notebook\n",
    "LANDMARK_FILES_DIR = \"../data/asl-signs/train_landmark_files\"\n",
    "TRAIN_FILE = \"../data/asl-signs/train.csv\"\n",
    "label_map = json.load(open(\"../data/asl-signs/sign_to_prediction_index_map.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from kaggle competition to load test data\n",
    "ROWS_PER_FRAME = 543\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    #defines which columns will be read from the file\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    #calculates the number of frames in the data by dividing the length of the data by the number of rows per frame\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    #reshapes the data into a 3D array with shape (n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_hand_percentage(x):\n",
    "    #calculates percentage of right hand usage\n",
    "    right = tf.gather(x, right_hand_landmarks, axis=1)\n",
    "    left = tf.gather(x, left_hand_landmarks, axis=1)\n",
    "    right_count = tf.reduce_sum(tf.where(tf.math.is_nan(right), tf.zeros_like(right), tf.ones_like(right)))\n",
    "    left_count = tf.reduce_sum(tf.where(tf.math.is_nan(left), tf.zeros_like(left), tf.ones_like(left)))\n",
    "    return right_count / (left_count+right_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "# NUmber of frames that will be used for averaging - after resizing (?)\n",
    "NUM_FRAMES = 15\n",
    "#count of segments the sequences will be cut into\n",
    "SEGMENTS = 3\n",
    "\n",
    "# Landmarks for specific types (hand, face, pose)\n",
    "FACE = [0, 468]\n",
    "LEFT_HAND_OFFSET = 468\n",
    "POSE_OFFSET = LEFT_HAND_OFFSET+21\n",
    "RIGHT_HAND_OFFSET = POSE_OFFSET+33\n",
    "\n",
    "## defining landmarks that will be merged\n",
    "averaging_sets = [[0, 468], [POSE_OFFSET, 33]]\n",
    "# 40 landmarks for lips\n",
    "lip_landmarks = [61, 185, 40, 39, 37,  0, 267, 269, 270, 409,\n",
    "                 291,146, 91,181, 84, 17, 314, 405, 321, 375, \n",
    "                 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, \n",
    "                 95, 88, 178, 87, 14,317, 402, 318, 324, 308]\n",
    "#defines landmarks for hands\n",
    "left_hand_landmarks = list(range(LEFT_HAND_OFFSET, LEFT_HAND_OFFSET+21))\n",
    "right_hand_landmarks = list(range(RIGHT_HAND_OFFSET, RIGHT_HAND_OFFSET+21))\n",
    "\n",
    "#generating list with all landmarks used for preprocessing\n",
    "point_landmarks = [item for sublist in [lip_landmarks, left_hand_landmarks, right_hand_landmarks] for item in sublist]\n",
    "\n",
    "#calculating sum of total landmarks used\n",
    "LANDMARKS = len(point_landmarks) + len(averaging_sets)\n",
    "print(LANDMARKS)\n",
    "\n",
    "#defining input shape for model\n",
    "INPUT_SHAPE = (NUM_FRAMES,LANDMARKS*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_nan_mean(x, axis=0):\n",
    "    #calculates the mean of a TensorFlow tensor x along a specified axis while ignoring any NaN values in the tensor.\n",
    "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis)\n",
    "\n",
    "def tf_nan_std(x, axis=0):\n",
    "    #calculates the standard deviation of a tensor x along a specified axis, while ignoring any NaN values in the tensor\n",
    "    d = x - tf_nan_mean(x, axis=axis)\n",
    "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis))\n",
    "\n",
    "def flatten_means_and_stds(x, axis=0):\n",
    "    # Get means and stds\n",
    "    x_mean = tf_nan_mean(x, axis=0)\n",
    "    x_std  = tf_nan_std(x,  axis=0)\n",
    "    #concats mean and std values for each sequence\n",
    "    x_out = tf.concat([x_mean, x_std], axis=0)\n",
    "    x_out = tf.reshape(x_out, (1, INPUT_SHAPE[1]*2))\n",
    "    # replaces NaN values with zeros\n",
    "    x_out = tf.where(tf.math.is_finite(x_out), x_out, tf.zeros_like(x_out))\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Feature Preprocessing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(1, 5796), dtype=tf.float32, name=None), name='feature_gen/concat_5:0', description=\"created by layer 'feature_gen'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5796), dtype=float32, numpy=\n",
       "array([[ 5.7140142e-01,  4.6732509e-01, -2.4906856e-05, ...,\n",
       "         3.8143307e-01,  8.0332047e-01, -1.0697230e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating preprocessing layer that will be added to final model\n",
    "class FeatureGen(tf.keras.layers.Layer):\n",
    "    #defines custom tensorflow layer \n",
    "    def __init__(self):\n",
    "        #initializes layer\n",
    "        super(FeatureGen, self).__init__()\n",
    "    \n",
    "    def call(self, x_in):\n",
    "        #generates list with mean values for landmarks that will be merged\n",
    "        x_list = [tf.expand_dims(tf_nan_mean(x_in[:, av_set[0]:av_set[0]+av_set[1], :], axis=1), axis=1) for av_set in averaging_sets]\n",
    "        #extracts specific columns from a 3D input tensor x_in defined by landmarks\n",
    "        x_list.append(tf.gather(x_in, point_landmarks, axis=1))\n",
    "        #concatenates the two tensors from above along axis 1/columns\n",
    "        x = tf.concat(x_list, 1)\n",
    "        #x is now our current tensor with mean values for those landmarks that were merged; and coordinates for all other landmarks\n",
    "        # its shape is n, 84, 3 with n being number of frames\n",
    "        \n",
    "        #padding of sequences so length can be divided by 3\n",
    "        x_padded = x\n",
    "        for i in range(SEGMENTS):\n",
    "            #p0 is equal to 1 if the number of rows cannot be divided by 3 and the current iteration index i is odd, and 0 otherwise\n",
    "            p0 = tf.where( ((tf.shape(x_padded)[0] % SEGMENTS) > 0) & ((i % 2) != 0) , 1, 0)\n",
    "            #p1 is equal to 1 if the number of rows cannot be divided by 3 and the current iteration index i is even, and 0 otherwise\n",
    "            p1 = tf.where( ((tf.shape(x_padded)[0] % SEGMENTS) > 0) & ((i % 2) == 0) , 1, 0)\n",
    "            #specifies the amount of padding to be added to each dimension. The first dimension is padded with p0 zeros at the top and p1 zeros at the bottom. \n",
    "            #The second and third dimensions are not padded.\n",
    "            paddings = [[p0, p1], [0, 0], [0, 0]]\n",
    "            #mode symmetric: the values at the edges of the tensor are mirrored\n",
    "            x_padded = tf.pad(x_padded, paddings, mode=\"SYMMETRIC\")\n",
    "            \n",
    "        #cut sequence in 3 parts and calculate mean and std for each part\n",
    "        x_list = tf.split(x_padded, SEGMENTS)\n",
    "        x_list = [flatten_means_and_stds(_x, axis=0) for _x in x_list]\n",
    "\n",
    "        #Add mean and std for whole sequence (?)\n",
    "        x_list.append(flatten_means_and_stds(x, axis=0))\n",
    "        \n",
    "        ## Resize only dimension 0. Resize can't handle nan, so replace nan with that dimension's avg value to reduce impact.\n",
    "        x = tf.image.resize(tf.where(tf.math.is_finite(x), x, tf_nan_mean(x, axis=0)), [NUM_FRAMES, LANDMARKS])\n",
    "        x = tf.reshape(x, (1, INPUT_SHAPE[0]*INPUT_SHAPE[1]))\n",
    "        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
    "        x_list.append(x)\n",
    "        x = tf.concat(x_list, axis=1)\n",
    "        return x\n",
    "    \n",
    "#define converter using generated layer\n",
    "feature_converter = FeatureGen()\n",
    "\n",
    "## One tests symbolic tensor, the other tests real data.\n",
    "print(feature_converter(tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")))\n",
    "\n",
    "#file path for kaggle\n",
    "#feature_converter(load_relevant_data_subset(f'/kaggle/input/asl-signs/{pd.read_csv(TRAIN_FILE).path[1]}'))\n",
    "\n",
    "#file path for local notebook\n",
    "#tests preprocessing layer with parquet file\n",
    "feature_converter(load_relevant_data_subset(f'../data/asl-signs/{pd.read_csv(TRAIN_FILE).path[1]}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/sf/vbyxyw2d051_vj10w2zctzz80000gn/T/ipykernel_13888/2734168791.py:7: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity with explicit device placement instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:00<00:00, 124.77it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_row(row, right_handed=True):\n",
    "    #for kaggle\n",
    "    #x = load_relevant_data_subset(os.path.join(\"/kaggle/input/asl-signs\", row[1].path))\n",
    "\n",
    "    #for local notebook\n",
    "    #loads data from parquet file\n",
    "    x = load_relevant_data_subset(os.path.join(\"../data/asl-signs\", row[1].path))\n",
    "\n",
    "    #applies preprocessing layer to loaded data\n",
    "    x = feature_converter(tf.convert_to_tensor(x)).cpu().numpy()\n",
    "    #returns transformed x data and label of sign\n",
    "    return x, row[1].label\n",
    "\n",
    "#unnecessary information?!\n",
    "right_handed_signer = [26734, 28656, 25571, 62590, 29302, \n",
    "                       49445, 53618, 18796,  4718,  2044, \n",
    "                       37779, 30680]\n",
    "left_handed_signer  = [16069, 32319, 36257, 22343, 27610, \n",
    "                       61333, 34503, 55372, ]\n",
    "both_hands_signer   = [37055, ]\n",
    "\n",
    "messy = [29302, ]\n",
    "\n",
    "def convert_and_save_data():\n",
    "    #reads csv file\n",
    "    df = pd.read_csv(TRAIN_FILE)\n",
    "    #maps label number to sign column\n",
    "    df['label'] = df['sign'].map(label_map)\n",
    "    #sets number of total rows\n",
    "    total = df.shape[0]\n",
    "    #limits number of rows if quick_test is activated\n",
    "    if QUICK_TEST:\n",
    "        total = QUICK_LIMIT\n",
    "    #generates numpy array with zeros in shape (total number of rows, number of expected columns)\n",
    "    npdata = np.zeros((total, INPUT_SHAPE[0]*INPUT_SHAPE[1] + (SEGMENTS+1)*INPUT_SHAPE[1]*2))\n",
    "    nplabels = np.zeros(total)\n",
    "    #for loop iterates through each row in df dataframe\n",
    "    for i, row in tqdm(enumerate(df.iterrows()), total=total):\n",
    "        #load specific parquet file and save x and y data\n",
    "        (x,y) = convert_row(row)\n",
    "        #save x and y to specific row in numpy arrays\n",
    "        npdata[i,:] = x\n",
    "        nplabels[i] = y\n",
    "        #break if quick test is activated\n",
    "        if QUICK_TEST and i == QUICK_LIMIT - 1:\n",
    "            break\n",
    "        \n",
    "    #save as np file\n",
    "    np.save(\"../data/feature_data.npy\", npdata)\n",
    "    np.save(\"../data/feature_labels.npy\", nplabels)\n",
    "        \n",
    "convert_and_save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5796) (100,)\n",
      "(5796,) [ 5.18924236e-01  3.42620254e-01  1.48732506e-05 ...  6.35599792e-02\n",
      "  5.70323110e-01 -1.20788895e-01]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "X = np.load(\"../data/feature_data.npy\")\n",
    "y = np.load(\"../data/feature_labels.npy\")\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "print(X[0, :].shape, X[0, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
