{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Code from kaggle evaluation site\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference is performed (roughly) as follows, ignoring details like how we manage multiple videos:\n",
    "import tflite_runtime.interpreter as tflite\n",
    "interpreter = tflite.Interpreter(model_path)\n",
    "\n",
    "found_signatures = list(interpreter.get_signature_list().keys())\n",
    "\n",
    "if REQUIRED_SIGNATURE not in found_signatures:\n",
    "    raise KernelEvalException('Required input signature not found.')\n",
    "\n",
    "prediction_fn = interpreter.get_signature_runner(\"serving_default\")\n",
    "output = prediction_fn(inputs=frames)\n",
    "sign = np.argmax(output[\"outputs\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/jvthunder/lstm-baseline-for-starters-sign-language/notebook\n",
    "\n",
    "In this competition, we should submit the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(inference_model)\n",
    "tflite_model = converter.convert()\n",
    "model_path = \"model.tflite\"\n",
    "\n",
    "# submit the model\n",
    "with open(model_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "!zip submission.zip $model_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/asl-signs/discussion/390182\n",
    "\n",
    "Also explains conversion from Keras to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow - Loading data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/roberthatch/gislr-feature-data-on-the-shoulders/notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I understand it correctly, the flow is as follow:\n",
    "\n",
    "1. Convert x_ into x containing avg face, avg pose, lips, left hand, right hand for every frame, e.g. [23, 84, 3]\n",
    "2. Pad x such that first dim is divisible by 3: [23, 84, 3] -> [24, 84, 3]\n",
    "3. Split padded x into three parts, and for each part, compute mean and std over frames, concat and flatten: [8, 84, 3] -> [2, 84, 3] -> [1, 504]\n",
    "4. Add flattened mean and std of x to features list, which now contains means and stds of the three parts + overall mean and std\n",
    "5. Resize x to [15, 84, 3], flatten and append it to features list\n",
    "\n",
    "* final shape of data: x (94477, 5796) and y (94477,)\n",
    "* takes ca 15 minutes to compile whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "import os\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit dataset for quick test\n",
    "QUICK_TEST = False\n",
    "QUICK_LIMIT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Kaggle\n",
    "# LANDMARK_FILES_DIR = \"/kaggle/input/asl-signs/train_landmark_files\"\n",
    "# TRAIN_FILE = \"/kaggle/input/asl-signs/train.csv\"\n",
    "# label_map = json.load(open(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\", \"r\"))\n",
    "\n",
    "#for local notebook\n",
    "LANDMARK_FILES_DIR = \"../data/asl-signs/train_landmark_files\"\n",
    "TRAIN_FILE = \"../data/asl-signs/train.csv\"\n",
    "label_map = json.load(open(\"../data/asl-signs/sign_to_prediction_index_map.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from kaggle competition to load test data\n",
    "ROWS_PER_FRAME = 543\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_hand_percentage(x):\n",
    "    right = tf.gather(x, right_hand_landmarks, axis=1)\n",
    "    left = tf.gather(x, left_hand_landmarks, axis=1)\n",
    "    right_count = tf.reduce_sum(tf.where(tf.math.is_nan(right), tf.zeros_like(right), tf.ones_like(right)))\n",
    "    left_count = tf.reduce_sum(tf.where(tf.math.is_nan(left), tf.zeros_like(left), tf.ones_like(left)))\n",
    "    return right_count / (left_count+right_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "NUM_FRAMES = 15\n",
    "SEGMENTS = 3\n",
    "\n",
    "LEFT_HAND_OFFSET = 468\n",
    "POSE_OFFSET = LEFT_HAND_OFFSET+21\n",
    "RIGHT_HAND_OFFSET = POSE_OFFSET+33\n",
    "\n",
    "## average over the entire face, and the entire 'pose'\n",
    "averaging_sets = [[0, 468], [POSE_OFFSET, 33]]\n",
    "\n",
    "lip_landmarks = [61, 185, 40, 39, 37,  0, 267, 269, 270, 409,\n",
    "                 291,146, 91,181, 84, 17, 314, 405, 321, 375, \n",
    "                 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, \n",
    "                 95, 88, 178, 87, 14,317, 402, 318, 324, 308]\n",
    "left_hand_landmarks = list(range(LEFT_HAND_OFFSET, LEFT_HAND_OFFSET+21))\n",
    "right_hand_landmarks = list(range(RIGHT_HAND_OFFSET, RIGHT_HAND_OFFSET+21))\n",
    "\n",
    "point_landmarks = [item for sublist in [lip_landmarks, left_hand_landmarks, right_hand_landmarks] for item in sublist]\n",
    "\n",
    "LANDMARKS = len(point_landmarks) + len(averaging_sets)\n",
    "print(LANDMARKS)\n",
    "INPUT_SHAPE = (NUM_FRAMES,LANDMARKS*3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_nan_mean(x, axis=0):\n",
    "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis)\n",
    "\n",
    "def tf_nan_std(x, axis=0):\n",
    "    d = x - tf_nan_mean(x, axis=axis)\n",
    "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis))\n",
    "\n",
    "def flatten_means_and_stds(x, axis=0):\n",
    "    # Get means and stds\n",
    "    x_mean = tf_nan_mean(x, axis=0)\n",
    "    x_std  = tf_nan_std(x,  axis=0)\n",
    "\n",
    "    x_out = tf.concat([x_mean, x_std], axis=0)\n",
    "    x_out = tf.reshape(x_out, (1, INPUT_SHAPE[1]*2))\n",
    "    x_out = tf.where(tf.math.is_finite(x_out), x_out, tf.zeros_like(x_out))\n",
    "    return x_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Feature Preprocessing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(1, 5796), dtype=tf.float32, name=None), name='feature_gen_2/concat_5:0', description=\"created by layer 'feature_gen_2'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5796), dtype=float32, numpy=\n",
       "array([[ 5.7140142e-01,  4.6732509e-01, -2.4906856e-05, ...,\n",
       "         3.8143307e-01,  8.0332047e-01, -1.0697230e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureGen(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(FeatureGen, self).__init__()\n",
    "    \n",
    "    def call(self, x_in):\n",
    "#         print(right_hand_percentage(x))\n",
    "        x_list = [tf.expand_dims(tf_nan_mean(x_in[:, av_set[0]:av_set[0]+av_set[1], :], axis=1), axis=1) for av_set in averaging_sets]\n",
    "        x_list.append(tf.gather(x_in, point_landmarks, axis=1))\n",
    "        x = tf.concat(x_list, 1)\n",
    "\n",
    "        x_padded = x\n",
    "        for i in range(SEGMENTS):\n",
    "            p0 = tf.where( ((tf.shape(x_padded)[0] % SEGMENTS) > 0) & ((i % 2) != 0) , 1, 0)\n",
    "            p1 = tf.where( ((tf.shape(x_padded)[0] % SEGMENTS) > 0) & ((i % 2) == 0) , 1, 0)\n",
    "            paddings = [[p0, p1], [0, 0], [0, 0]]\n",
    "            x_padded = tf.pad(x_padded, paddings, mode=\"SYMMETRIC\")\n",
    "        x_list = tf.split(x_padded, SEGMENTS)\n",
    "        x_list = [flatten_means_and_stds(_x, axis=0) for _x in x_list]\n",
    "\n",
    "        x_list.append(flatten_means_and_stds(x, axis=0))\n",
    "        \n",
    "        ## Resize only dimension 0. Resize can't handle nan, so replace nan with that dimension's avg value to reduce impact.\n",
    "        x = tf.image.resize(tf.where(tf.math.is_finite(x), x, tf_nan_mean(x, axis=0)), [NUM_FRAMES, LANDMARKS])\n",
    "        x = tf.reshape(x, (1, INPUT_SHAPE[0]*INPUT_SHAPE[1]))\n",
    "        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
    "        x_list.append(x)\n",
    "        x = tf.concat(x_list, axis=1)\n",
    "        return x\n",
    "\n",
    "feature_converter = FeatureGen()\n",
    "\n",
    "## One tests symbolic tensor, the other tests real data.\n",
    "print(feature_converter(tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")))\n",
    "\n",
    "#for kaggle\n",
    "#feature_converter(load_relevant_data_subset(f'/kaggle/input/asl-signs/{pd.read_csv(TRAIN_FILE).path[1]}'))\n",
    "\n",
    "#for local notebook\n",
    "feature_converter(load_relevant_data_subset(f'../data/asl-signs/{pd.read_csv(TRAIN_FILE).path[1]}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94477/94477 [12:50<00:00, 122.67it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_row(row, right_handed=True):\n",
    "    #for kaggle\n",
    "    #x = load_relevant_data_subset(os.path.join(\"/kaggle/input/asl-signs\", row[1].path))\n",
    "    #for local notebook\n",
    "    x = load_relevant_data_subset(os.path.join(\"../data/asl-signs\", row[1].path))\n",
    "    \n",
    "    x = feature_converter(tf.convert_to_tensor(x)).cpu().numpy()\n",
    "    return x, row[1].label\n",
    "\n",
    "right_handed_signer = [26734, 28656, 25571, 62590, 29302, \n",
    "                       49445, 53618, 18796,  4718,  2044, \n",
    "                       37779, 30680]\n",
    "left_handed_signer  = [16069, 32319, 36257, 22343, 27610, \n",
    "                       61333, 34503, 55372, ]\n",
    "both_hands_signer   = [37055, ]\n",
    "\n",
    "messy = [29302, ]\n",
    "\n",
    "def convert_and_save_data():\n",
    "    df = pd.read_csv(TRAIN_FILE)\n",
    "    df['label'] = df['sign'].map(label_map)\n",
    "    total = df.shape[0]\n",
    "    if QUICK_TEST:\n",
    "        total = QUICK_LIMIT\n",
    "    npdata = np.zeros((total, INPUT_SHAPE[0]*INPUT_SHAPE[1] + (SEGMENTS+1)*INPUT_SHAPE[1]*2))\n",
    "    nplabels = np.zeros(total)\n",
    "    for i, row in tqdm(enumerate(df.iterrows()), total=total):\n",
    "        (x,y) = convert_row(row)\n",
    "        npdata[i,:] = x\n",
    "        nplabels[i] = y\n",
    "        if QUICK_TEST and i == QUICK_LIMIT - 1:\n",
    "            break\n",
    "        \n",
    "    #save as np file\n",
    "    np.save(\"../data/feature_data.npy\", npdata)\n",
    "    np.save(\"../data/feature_labels.npy\", nplabels)\n",
    "        \n",
    "convert_and_save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94477, 5796) (94477,)\n",
      "(5796,) [ 5.18924236e-01  3.42620254e-01  1.48732506e-05 ...  6.35599792e-02\n",
      "  5.70323110e-01 -1.20788895e-01]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "X = np.load(\"../data/feature_data.npy\")\n",
    "y = np.load(\"../data/feature_labels.npy\")\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "print(X[0, :].shape, X[0, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rocket Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sktime in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.1.0 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from sktime) (1.3.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from sktime) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn<1.3.0,>=0.24.0 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from sktime) (1.0)\n",
      "Requirement already satisfied: numba>=0.53 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from sktime) (0.56.4)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from sktime) (1.2.13)\n",
      "Requirement already satisfied: numpy<1.25,>=1.21.0 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from sktime) (1.23.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from deprecated>=1.2.13->sktime) (1.14.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from numba>=0.53->sktime) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from numba>=0.53->sktime) (58.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from pandas<2.0.0,>=1.1.0->sktime) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from pandas<2.0.0,>=1.1.0->sktime) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.1.0->sktime) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sktime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.classification.kernel_based import RocketClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RocketClassifier(num_kernels=500) \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of used landmarks: 104\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
