{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow - Loading data - Adjusting the layer to our needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/roberthatch/gislr-feature-data-on-the-shoulders/notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates a tensorflow preprocessing layer that transforms the whole dataset of single parquet files into numpy arrays.\n",
    "\n",
    "The flow is as follow:\n",
    "\n",
    "***preprocessing layer:***\n",
    "1. drop z coordinate if desired (this would reduce number of coordinates to 2; following array shapes show number for 3 coordinates)\n",
    "2. Convert input into x containing avg face, lips, upper pose landmarks, left hand, right hand for every frame, \n",
    "    e.g. [23, 106, 3] = (number of frames, landmarks, coordinates)\n",
    "3. Pad x or cut x such that the length is as defined (e.g. length = 30 --> [30, 106, 3])  = (number of frames, landmarks, coordinates)\n",
    "4. interpolate single missing values, then replace NaN values with zero\n",
    "4. Resize it to either flattened or 3 dimensional array:\n",
    "    * 3D: ( [1, 30, 318] = (1 row, number of frames, landmarks * coordinates) \n",
    "    * or flattened: [1, 9540])  = (1 row, number of frames * landmarks * coordinates)\n",
    "\n",
    "***looping through csv file ***\n",
    "\n",
    "By looping through the csv file each parquet file will be loaded and the required data will be extracted and transformed by running it through the preprocessing layer.\n",
    "Then the data will be added to our final numpy array of all recordings. If the recording is exceeding defined length limits it will be removed from the dataset.\n",
    "\n",
    "* final shape of data: flattened: x (94477, 5796) and y (94477,) or unflattened: (94477, 30, 212) (94477,)\n",
    "* shape also depends on selected landmarks and coordinates and migth vary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (4.65.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "import os\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file paths for Kaggle\n",
    "# LANDMARK_FILES_DIR = \"/kaggle/input/asl-signs/train_landmark_files\"\n",
    "# TRAIN_FILE = \"/kaggle/input/asl-signs/train.csv\"\n",
    "# OUTPUT = \"\"\n",
    "# label_map = json.load(open(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\", \"r\"))\n",
    "\n",
    "#for local notebook, adjust file paths here if required\n",
    "LANDMARK_FILES_DIR = \"../data/asl-signs/\"\n",
    "TRAIN_FILE = \"../data/asl-signs/train.csv\"\n",
    "OUTPUT = \"../data/\" #path to save x and y files\n",
    "label_map = json.load(open(\"../data/asl-signs/sign_to_prediction_index_map.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown', 'callonphone', 'cow', 'cry', 'dad', 'fireman', 'frog', 'gum', 'icecream', 'minemy', 'nose', 'owl', 'please', 'radio', 'shhh', 'shirt', 'tomorrow', 'uncle', 'water', 'who']\n"
     ]
    }
   ],
   "source": [
    "#getting signs for specific label numbers\n",
    "#converting strings in list to numbers\n",
    "listsigns = ['31.0', '194.0', '165.0', '234.0', '90.0', '195.0', '239.0', '34.0', '143.0', '182.0', '221.0', '173.0', '55.0', '50.0', '82.0', '52.0', '122.0', '228.0', '155.0', '103.0']\n",
    "listsigns = [float(x) for x in listsigns]\n",
    "#get signs from dictionary\n",
    "signs = []\n",
    "for key, value in label_map.items():\n",
    "    if value in listsigns:\n",
    "        signs.append(key)\n",
    "\n",
    "print(signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of used landmarks: 43\n",
      "(22, 129)\n"
     ]
    }
   ],
   "source": [
    "#limit dataset for quick test\n",
    "QUICK_TEST = False\n",
    "QUICK_LIMIT = 500\n",
    "\n",
    "#Define length of sequences for padding or cutting; 22 is the median length of all sequences\n",
    "LENGTH = 22\n",
    "\n",
    "#define min or max length of sequences; sequences too long/too short will be dropped\n",
    "#max value of 92 was defined by calculating the interquartile range\n",
    "MIN_LENGTH = 2\n",
    "MAX_LENGTH = 120\n",
    "\n",
    "#final data will be flattened, if false data will be 3 dimensional\n",
    "FLATTEN = False\n",
    "\n",
    "#define initialization of numpy array \n",
    "ARRAY = False #(True=Zeros, False=empty values)\n",
    "\n",
    "#Define padding mode \n",
    "#1 = padding at start&end; 2 = padding at end; 3 = no padding, 4 = copy first/lastframe, 5 = copy last frame)\n",
    "#Note: Mode 3 will give you an error due to different lengths, working on that\n",
    "PADDING = 2\n",
    "CONSTANT_VALUE = 0 #only required for mode 1 and 2; enter tf.constant(float('nan')) for NaN\n",
    "\n",
    "#define if z coordinate will be dropped\n",
    "DROP_Z = False\n",
    "\n",
    "#mirror, flips x coordinate for data augmentation\n",
    "MIRROR = True\n",
    "\n",
    "#define if csv file should be filtered\n",
    "CSV_FILTER  = False\n",
    "#define how many participants for test set\n",
    "TEST_COUNT = 5 #5 participants account for ca 23% of dataset\n",
    "#generate test or train dataset (True = Train dataset; False = Test dataset)\n",
    "#TRAIN = True #only works if CSV_FILTER is activated\n",
    "TRAIN = True\n",
    "\n",
    "#filter for specific signs\n",
    "SIGN_FILTER = True\n",
    "sign_list = [31.0, 194.0, 165.0, 234.0, 90.0, 195.0, 239.0, 34.0, 143.0, 182.0, 221.0, 173.0, 55.0, 50.0, 82.0, 52.0, 122.0, 228.0, 155.0, 103.0]\n",
    "#Best 20 sings are: [31.0, 194.0, 165.0, 234.0, 90.0, 195.0, 239.0, 34.0, 143.0, 182.0, 221.0, 173.0, 55.0, 50.0, 82.0, 52.0, 122.0, 228.0, 155.0, 103.0]\n",
    "\n",
    "#define filenames for x and y:\n",
    "feature_data = 'X_20_fz' #x data\n",
    "feature_labels = 'y_20_fz' #y data\n",
    "\n",
    "#use for test dataset\n",
    "#feature_data = 'X_test_h6' #x data\n",
    "#feature_labels = 'y_test_h6' #y data\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "#Defining Landmarks\n",
    "#index ranges for each landmark type\n",
    "#dont change these landmarks\n",
    "FACE = list(range(0, 468))\n",
    "FACE_OUTLINE = [  0,   1,   4,   5,  10,  11,  12,  13,  14,  15,  16,  17,  19,\n",
    "        21,  34,  37,  38,  39,  44,  45,  46,  51,  52,  53,  54,  58,\n",
    "        61,  62,  63,  65,  66,  67,  68,  69,  70,  71,  72,  76,  78,\n",
    "        82,  84,  85,  86,  87,  93, 103, 104, 105, 107, 108, 109, 116,\n",
    "       123, 125, 127, 132, 135, 136, 137, 138, 139, 140, 143, 147, 148,\n",
    "       149, 150, 151, 152, 156, 162, 169, 170, 171, 172, 175, 176, 177,\n",
    "       180, 181, 192, 199, 208, 213, 215, 220, 227, 234, 237, 251, 264,\n",
    "       267, 268, 269, 274, 275, 276, 281, 282, 283, 284, 288, 293, 295,\n",
    "       296, 297, 298, 299, 300, 301, 302, 314, 315, 316, 317, 323, 332,\n",
    "       333, 334, 336, 337, 338, 356, 361, 364, 365, 366, 367, 368, 369,\n",
    "       377, 378, 379, 383, 389, 394, 395, 396, 397, 400, 401, 405, 428,\n",
    "       435, 440, 444, 445, 447, 454, 457]\n",
    "LEFT_HAND = list(range(468, 489))\n",
    "POSE = list(range(489, 522))\n",
    "POSE_UPPER = list(range(489, 510))\n",
    "RIGHT_HAND = list(range(522, 543))\n",
    "LIPS = [61, 185, 40, 39, 37,  0, 267, 269, 270, 409,\n",
    "                 291,146, 91,181, 84, 17, 314, 405, 321, 375, \n",
    "                 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, \n",
    "                 95, 88, 178, 87, 14,317, 402, 318, 324, 308]\n",
    "lipsUpperOuter= [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291]\n",
    "lipsLowerOuter= [146, 91, 181, 84, 17, 314, 405, 321, 375, 291]\n",
    "lipsUpperInner= [78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308]\n",
    "lipsLowerInner= [78, 95, 88, 178, 87, 14, 317, 402, 318, 324, 308]\n",
    "#defining landmarks that will be merged\n",
    "averaging_sets = []\n",
    "\n",
    "#generating list with all landmarks selected for preprocessing\n",
    "#change landmarks you want to use here:\n",
    "point_landmarks_right = RIGHT_HAND + lipsUpperInner + lipsLowerInner\n",
    "point_landmarks_left = LEFT_HAND + lipsUpperInner + lipsLowerInner\n",
    "\n",
    "#calculating sum of total landmarks used\n",
    "LANDMARKS = len(point_landmarks_right) + len(averaging_sets)\n",
    "print(f'Total count of used landmarks: {LANDMARKS}')\n",
    "\n",
    "#defining input shape for model\n",
    "if DROP_Z:\n",
    "    INPUT_SHAPE = (LENGTH,LANDMARKS*2)\n",
    "else:\n",
    "    INPUT_SHAPE = (LENGTH,LANDMARKS*3)\n",
    "print(INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    #defines which columns will be read from the file\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    #calculates the number of frames in the data by dividing the length of the data by the number of rows per frame\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    #reshapes the data into a 3D array with shape (n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_hand_percentage(x):\n",
    "    #calculates percentage of right hand usage\n",
    "    right = tf.gather(x, RIGHT_HAND, axis=1)\n",
    "    left = tf.gather(x, LEFT_HAND, axis=1)\n",
    "    right_count = tf.reduce_sum(tf.where(tf.math.is_nan(right), tf.zeros_like(right), tf.ones_like(right)))\n",
    "    left_count = tf.reduce_sum(tf.where(tf.math.is_nan(left), tf.zeros_like(left), tf.ones_like(left)))\n",
    "    return right_count / (left_count+right_count)\n",
    "\n",
    "def calc_finger_angles(x, joint_list):\n",
    "    #initialization of empty np array\n",
    "    x_out = np.zeros((len(x),len(joint_list),1))\n",
    "    #looping through list of landmarks required for one finger\n",
    "    for i in range(len(joint_list)):\n",
    "        #collecting all coordinates for one finger for all frames\n",
    "        x_joint = tf.gather(x, joint_list[i], axis=1)\n",
    "        #Loop through joint sets \n",
    "        for frame in range(len(x)):\n",
    "                a = np.array([x_joint[frame][0][0], x_joint[frame][0][1]]) # First coord\n",
    "                b = np.array([x_joint[frame][1][0], x_joint[frame][1][1]]) # Second coord\n",
    "                c = np.array([x_joint[frame][2][0], x_joint[frame][2][1]]) # Third coord\n",
    "\n",
    "                radians = np.arctan2(c[1] - b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "                angle = np.abs(radians*180.0/np.pi)\n",
    "                    \n",
    "                if angle > 180.0:\n",
    "                    angle = 360-angle\n",
    "                \n",
    "                x_out[frame][i]= angle\n",
    "\n",
    "    return x_out               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_nan_mean(x, axis=0):\n",
    "    #calculates the mean of a TensorFlow tensor x along a specified axis while ignoring any NaN values in the tensor.\n",
    "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis)\n",
    "\n",
    "def tf_nan_std(x, axis=0):\n",
    "    #calculates the standard deviation of a tensor x along a specified axis, while ignoring any NaN values in the tensor\n",
    "    d = x - tf_nan_mean(x, axis=axis)\n",
    "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis))\n",
    "\n",
    "#this function is only required if mean and std will be calculated for specific segments of the data\n",
    "def flatten_means_and_stds(x, axis=0):\n",
    "    #Get means and stds\n",
    "    x_mean = tf_nan_mean(x, axis=0)\n",
    "    x_std  = tf_nan_std(x,  axis=0)\n",
    "    #concats mean and std values for each sequence\n",
    "    x_out = tf.concat([x_mean, x_std], axis=0)\n",
    "    x_out = tf.reshape(x_out, (1, INPUT_SHAPE[1]*2))\n",
    "    #replaces NaN values with zeros\n",
    "    x_out = tf.where(tf.math.is_finite(x_out), x_out, tf.zeros_like(x_out))\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Feature Preprocessing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating preprocessing layer that will be added to final model\n",
    "class FeatureGen(tf.keras.layers.Layer):\n",
    "    #defines custom tensorflow layer \n",
    "    def __init__(self):\n",
    "        #initializes layer\n",
    "        super(FeatureGen, self).__init__()\n",
    "    \n",
    "    def call(self, x_in, MIRROR=False):\n",
    "        #drop z coordinates if required\n",
    "        if DROP_Z:\n",
    "            x_in = x_in[:, :, 0:2]\n",
    "        if MIRROR:\n",
    "            #flipping x coordinates\n",
    "            x_in = np.array(x_in)\n",
    "            x_in[:, :, 0] = (x_in[:, :, 0]-1)*(-1)\n",
    "            x_in = tf.convert_to_tensor(x_in)\n",
    "\n",
    "        #generates list with mean values for landmarks that will be merged\n",
    "        x_list = [tf.expand_dims(tf_nan_mean(x_in[:, av_set[0]:av_set[0]+av_set[1], :], axis=1), axis=1) for av_set in averaging_sets]\n",
    "        \n",
    "        #extracts specific columns from input x_in defined by landmarks\n",
    "        handedness = right_hand_percentage(x_in)\n",
    "        if handedness > 0.5:\n",
    "            x_list.append(tf.gather(x_in, point_landmarks_right, axis=1))\n",
    "        else: \n",
    "            x_list.append(tf.gather(x_in, point_landmarks_left, axis=1))\n",
    "\n",
    "        #concatenates the two tensors from above along axis 1/columns\n",
    "        x = tf.concat(x_list, 1)\n",
    "\n",
    "        #padding to desired length of sequence (defined by LENGTH)\n",
    "        #get current number of rows\n",
    "        x_padded = x\n",
    "        current_rows = tf.shape(x_padded)[0]\n",
    "        #if current number of rows is greater than desired number of rows, truncate excess rows\n",
    "        if current_rows > LENGTH:\n",
    "            x_padded = x_padded[:LENGTH, :, :]\n",
    "\n",
    "        #if current number of rows is less than desired number of rows, add padding\n",
    "        elif current_rows < LENGTH:\n",
    "            #calculate amount of padding needed\n",
    "            pad_rows = LENGTH - current_rows\n",
    "\n",
    "            if PADDING ==4: #copy first/last frame\n",
    "                if pad_rows %2 == 0: #if pad_rows is even\n",
    "                    padding_front = tf.repeat(x_padded[0:1, :], pad_rows//2, axis=0)\n",
    "                    padding_back = tf.repeat(x_padded[-1:, :], pad_rows//2, axis=0)\n",
    "                else: #if pad_rows is odd\n",
    "                    padding_front = tf.repeat(x_padded[0:1, :], (pad_rows//2)+1, axis=0)\n",
    "                    padding_back = tf.repeat(x_padded[-1:, :], pad_rows//2, axis=0)\n",
    "                x_padded = tf.concat([padding_front, x_padded, padding_back], axis=0)\n",
    "            elif PADDING == 5: #copy last frame\n",
    "                padding_back = tf.repeat(x_padded[-1:, :], pad_rows, axis=0)\n",
    "                x_padded = tf.concat([x_padded, padding_back], axis=0)\n",
    "            else:\n",
    "                if PADDING ==1: #padding at start and end\n",
    "                    if pad_rows %2 == 0: #if pad_rows is even\n",
    "                        paddings = [[pad_rows//2, pad_rows//2], [0, 0], [0, 0]]\n",
    "                    else: #if pad_rows is odd\n",
    "                        paddings = [[pad_rows//2+1, pad_rows//2], [0, 0], [0, 0]]\n",
    "                elif PADDING ==2: #padding only at the end of sequence\n",
    "                    paddings = [[0, pad_rows], [0, 0], [0, 0]]\n",
    "                elif PADDING ==3: #no padding\n",
    "                    paddings = [[0, 0], [0, 0], [0, 0]]\n",
    "                x_padded = tf.pad(x_padded, paddings, mode='CONSTANT', constant_values=CONSTANT_VALUE)\n",
    "\n",
    "        x = x_padded\n",
    "        current_rows = tf.shape(x)[0]\n",
    "\n",
    "        #interpolate single missing values\n",
    "        x = pd.DataFrame(np.array(x).flatten()).interpolate(method='linear', limit=2, limit_direction='both')\n",
    "        #fill missing values with zeros\n",
    "        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
    "        \n",
    "        #reshape data to 2D or 3D array\n",
    "        if FLATTEN:\n",
    "            x = tf.reshape(x, (1, current_rows*INPUT_SHAPE[1]))\n",
    "        else:\n",
    "            x = tf.reshape(x, (1, current_rows, INPUT_SHAPE[1]))\n",
    "\n",
    "        return x\n",
    "\n",
    "#define converter using generated layer\n",
    "feature_converter = FeatureGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 22, 129), dtype=float32, numpy=\n",
       "array([[[ 1.77938476e-01,  7.67818928e-01, -2.48486742e-07, ...,\n",
       "          5.30708253e-01,  4.24927592e-01, -1.93983670e-02],\n",
       "        [ 2.06655979e-01,  7.44444609e-01, -1.88931210e-07, ...,\n",
       "          5.32789052e-01,  4.24572080e-01, -1.91066787e-02],\n",
       "        [ 2.27484822e-01,  7.34135747e-01, -1.38419338e-07, ...,\n",
       "          5.34244180e-01,  4.22210097e-01, -2.03100462e-02],\n",
       "        ...,\n",
       "        [-1.24098863e-02, -5.25800698e-03,  0.00000000e+00, ...,\n",
       "          5.32222271e-01,  3.99834335e-01, -2.04068236e-02],\n",
       "        [-1.32594220e-02, -6.11202093e-03,  0.00000000e+00, ...,\n",
       "          5.31390190e-01,  3.98376554e-01, -1.74602736e-02],\n",
       "        [-1.03909485e-02, -3.32162296e-03,  0.00000000e+00, ...,\n",
       "          5.29494345e-01,  3.99472326e-01, -1.88509431e-02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tests for generated layer\n",
    "#One tests symbolic tensor, the other tests real data.\n",
    "#print(feature_converter(tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")))\n",
    "\n",
    "#tests preprocessing layer with parquet file\n",
    "feature_converter((load_relevant_data_subset(f'{LANDMARK_FILES_DIR}{pd.read_csv(TRAIN_FILE).path[10]}')), MIRROR=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These signs are used as dataset: [31.0, 194.0, 165.0, 234.0, 90.0, 195.0, 239.0, 34.0, 143.0, 182.0, 221.0, 173.0, 55.0, 50.0, 82.0, 52.0, 122.0, 228.0, 155.0, 103.0].\n",
      "Together they have 7814 recordings.\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7814/7814.0 [00:58<00:00, 133.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020 sequences were removed because they are too long, which is 6.53% of the used dataset.\n",
      "0 sequences were removed because they are too short, which is 0.0% of the used dataset.\n",
      "-------------------------------------\n",
      "Shapes of the final datasets are:\n",
      "(14608, 22, 129) (14608,)\n"
     ]
    }
   ],
   "source": [
    "def convert_row(i, row, long_sequences, short_sequences, MIRROR=False):\n",
    "\n",
    "    #loads data from parquet file\n",
    "    x = load_relevant_data_subset(f'{LANDMARK_FILES_DIR}{row[1].path}')\n",
    "    \n",
    "    if MIRROR:\n",
    "        #applies preprocessing layer to loaded data\n",
    "        x = feature_converter(tf.convert_to_tensor(x), MIRROR=True).cpu().numpy()\n",
    "\n",
    "    else:\n",
    "        #if sequence is too long or too short its index will be added to list, so we can later remove them from dataset\n",
    "        if x.shape[0] < MIN_LENGTH:\n",
    "            short_sequences.append(i)\n",
    "        elif x.shape[0] > MAX_LENGTH:\n",
    "            long_sequences.append(i)\n",
    "\n",
    "        #applies preprocessing layer to loaded data\n",
    "        x = feature_converter(tf.convert_to_tensor(x)).cpu().numpy()\n",
    "\n",
    "\n",
    "    #returns transformed x data and label of sign\n",
    "    return x, row[1].label\n",
    "\n",
    "def convert_and_save_data():\n",
    "    #reads csv file\n",
    "    df = pd.read_csv(TRAIN_FILE)\n",
    "    #maps label number to sign column\n",
    "    df['label'] = df['sign'].map(label_map)\n",
    "    \n",
    "    #filter dataset for participant train/test split\n",
    "    if CSV_FILTER:      \n",
    "        #set random state\n",
    "        random.seed(RANDOM_STATE)\n",
    "        #get random participants from dataset and add to sample list, number of participants is defined in setup\n",
    "        sample_list = random.sample(df.groupby('participant_id').mean().index.values.tolist(), TEST_COUNT)\n",
    "        print(f'These participants are used as test set: {sample_list}.') \n",
    "        print(f'Together they have {df.query(f\"participant_id in {sample_list}\").shape[0]} recordings, {round(df.query(f\"participant_id in {sample_list}\").shape[0]/df.shape[0]*100,2)}% of the dataset.')\n",
    "        print('-------------------------------------')\n",
    "        if TRAIN:\n",
    "            #limit dataset to participants used for train set\n",
    "            df = df.query(f'participant_id not in {sample_list}')\n",
    "        else:\n",
    "            #limit dataset to participants used for test set\n",
    "            df = df.query(f'participant_id in {sample_list}')\n",
    "    if SIGN_FILTER:\n",
    "        df = df.query(f'label in {sign_list}')\n",
    "        print(f'These signs are used as dataset: {sign_list}.')\n",
    "        print(f'Together they have {df.shape[0]} recordings.')\n",
    "        print('-------------------------------------')\n",
    "\n",
    "    #sets number of total rows\n",
    "    total = df.shape[0]\n",
    "    if MIRROR:\n",
    "        total = total*2\n",
    "    #limits number of rows if quick_test is activated\n",
    "    if QUICK_TEST:\n",
    "        total = QUICK_LIMIT\n",
    "    \n",
    "    #generates numpy array with zeros in shape (total number of rows, number of expected columns)\n",
    "    if ARRAY: #initialize array with zeros\n",
    "        if FLATTEN:\n",
    "            npdata = np.zeros((total, INPUT_SHAPE[0]*INPUT_SHAPE[1]))\n",
    "        else:\n",
    "            npdata = np.zeros((total, INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "        nplabels = np.zeros(total)\n",
    "    else: #initialize empty array\n",
    "        if FLATTEN:\n",
    "            npdata = np.empty((total, INPUT_SHAPE[0]*INPUT_SHAPE[1]))\n",
    "        else:\n",
    "            npdata = np.empty((total, INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "        nplabels = np.empty(total)\n",
    "\n",
    "    #initializing lists for collecting too long and too short sequences\n",
    "    long_sequences = []\n",
    "    short_sequences = []\n",
    "\n",
    "    #for loop iterates through each row in df dataframe; i is index of the row and row accesses information in the row of df\n",
    "    #tqdm is used for showing progress bar\n",
    "    for i, row in tqdm(enumerate(df.iterrows()), total=total/2 if MIRROR else total):\n",
    "        #load specific parquet file, run preprocessing layer and save x and y data\n",
    "        (x,y) = convert_row(i, row, long_sequences, short_sequences, MIRROR=False)\n",
    "        #save x and y to specific row in prepared numpy arrays\n",
    "        npdata[i,:] = x\n",
    "        nplabels[i] = y\n",
    "\n",
    "        if MIRROR:\n",
    "            (x,y) = convert_row(i, row, long_sequences, short_sequences, MIRROR=True)\n",
    "            #save x and y to specific row in prepared numpy arrays\n",
    "            npdata[i+(total//2),:] = x\n",
    "            nplabels[i+(total//2)] = y\n",
    "\n",
    "        if QUICK_TEST and i*2 == QUICK_LIMIT - 2:\n",
    "            break\n",
    "\n",
    "    if MIRROR:\n",
    "        #we also need to add too long and too short sequences that were flipped to the lists for removal\n",
    "        long_sequences.extend([x + (total//2) for x in long_sequences])\n",
    "        short_sequences.extend([x + (total//2) for x in short_sequences])\n",
    "\n",
    "    #remove rows of sequences that are too long/too short\n",
    "    npdata = np.delete(npdata, obj = (long_sequences + short_sequences), axis=0)\n",
    "    nplabels = np.delete(nplabels, obj = (long_sequences + short_sequences), axis=0)\n",
    "\n",
    "    print (f'{len(long_sequences)} sequences were removed because they are too long, which is {round(len(long_sequences)/total*100,2)}% of the used dataset.')\n",
    "    print (f'{len(short_sequences)} sequences were removed because they are too short, which is {round(len(short_sequences)/total*100,2)}% of the used dataset.')\n",
    "    print('-------------------------------------')\n",
    "    print('Shapes of the final datasets are:')\n",
    "    print(npdata.shape, nplabels.shape)\n",
    "\n",
    "    #save as np file\n",
    "    np.save(f\"{OUTPUT}{feature_data}.npy\", npdata)\n",
    "    np.save(f\"{OUTPUT}{feature_labels}.npy\", nplabels)\n",
    "        \n",
    "convert_and_save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14608, 22, 129) (14608,)\n"
     ]
    }
   ],
   "source": [
    "#test of loading data\n",
    "X = np.load(f\"{OUTPUT}{feature_data}.npy\")\n",
    "y = np.load(f\"{OUTPUT}{feature_labels}.npy\")\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for encoding sign labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new label map with reduced sign number\n",
    "unique_values = sorted(list(set(y)))  # get a sorted list of unique values\n",
    "#creating new label map for reduced sign count\n",
    "new_label_map = {i: unique_values[i] for i in range(len(unique_values))}\n",
    "#mapping the new label map on y dataset\n",
    "y_new = np.array([list(new_label_map.keys())[list(new_label_map.values()).index(val)] for val in y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brown': 0, 'callonphone': 1, 'cow': 2, 'cry': 3, 'dad': 4, 'fireman': 5, 'frog': 6, 'gum': 7, 'icecream': 8, 'minemy': 9, 'nose': 10, 'owl': 11, 'please': 12, 'radio': 13, 'shhh': 14, 'shirt': 15, 'tomorrow': 16, 'uncle': 17, 'water': 18, 'who': 19}\n"
     ]
    }
   ],
   "source": [
    "#creating new dictionary for final new label map used for live prediction at later step\n",
    "new_dict = {}\n",
    "for k, v in new_label_map.items():\n",
    "    new_dict[list(label_map.keys())[int(v)]] = k\n",
    "print(new_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
