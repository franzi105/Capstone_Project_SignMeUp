{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow - Loading data - Adjusting the layer to our needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/roberthatch/gislr-feature-data-on-the-shoulders/notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates a tensorflow preprocessing layer that transforms the whole dataset of single parquet files into numpy arrays.\n",
    "\n",
    "The flow is as follow:\n",
    "\n",
    "***preprocessing layer:***\n",
    "1. drop z coordinate if desired (this would reduce number of coordinates to 2; following array shapes show number for 3 coordinates)\n",
    "2. Convert input into x containing avg face, lips, upper pose landmarks, left hand, right hand for every frame, \n",
    "    e.g. [23, 106, 3] = (number of frames, landmarks, coordinates)\n",
    "3. Pad x or cut x such that the length is as defined (e.g. length = 30 --> [30, 106, 3])\n",
    "4. replace NaN values with zero\n",
    "4. Resize it to either flattened or 3 dimensional array ( [1, 30, 318] or flattened: [1, 9540])\n",
    "\n",
    "***looping through csv file ***\n",
    "\n",
    "By looping through the csv file each parquet file will be loaded and the required data will be extracted and transformed by running it through the preprocessing layer.\n",
    "Then the data will be added to our final numpy array of all recordings.\n",
    "\n",
    "* final shape of data: flattened: x (94477, 5796) and y (94477,) or unflattened: (94477, 30, 212) (94477,)\n",
    "* shape also depends on selected landmarks and coordinates and migth vary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/franzi/neuefische/Capstone_Project_SignMeUp/.venv/lib/python3.9/site-packages (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "import os\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit dataset for quick test\n",
    "QUICK_TEST = False\n",
    "QUICK_LIMIT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Kaggle\n",
    "# LANDMARK_FILES_DIR = \"/kaggle/input/asl-signs/train_landmark_files\"\n",
    "# TRAIN_FILE = \"/kaggle/input/asl-signs/train.csv\"\n",
    "# label_map = json.load(open(\"/kaggle/input/asl-signs/sign_to_prediction_index_map.json\", \"r\"))\n",
    "\n",
    "#for local notebook\n",
    "LANDMARK_FILES_DIR = \"../data/asl-signs/train_landmark_files\"\n",
    "TRAIN_FILE = \"../data/asl-signs/train.csv\"\n",
    "label_map = json.load(open(\"../data/asl-signs/sign_to_prediction_index_map.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "#Define length of sequences for padding or cutting\n",
    "LENGTH = 30\n",
    "\n",
    "#final data will be flattened, if false data will be 3 dimensional\n",
    "FLATTEN = False\n",
    "\n",
    "#define if z coordinate will be dropped\n",
    "DROP_Z = True\n",
    "\n",
    "#Landmarks for specific types (hand, face, pose)\n",
    "FACE = [0, 468]\n",
    "LEFT_HAND_OFFSET = 468\n",
    "POSE_OFFSET = LEFT_HAND_OFFSET+21\n",
    "RIGHT_HAND_OFFSET = POSE_OFFSET+33\n",
    "\n",
    "##defining landmarks that will be merged\n",
    "averaging_sets = [[0, 468]]\n",
    "#40 landmarks for lips\n",
    "lip_landmarks = [61, 185, 40, 39, 37,  0, 267, 269, 270, 409,\n",
    "                 291,146, 91,181, 84, 17, 314, 405, 321, 375, \n",
    "                 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, \n",
    "                 95, 88, 178, 87, 14,317, 402, 318, 324, 308]\n",
    "\n",
    "#defines landmarks for hands\n",
    "pose_landmarks = list(range(POSE_OFFSET, POSE_OFFSET+23))\n",
    "left_hand_landmarks = list(range(LEFT_HAND_OFFSET, LEFT_HAND_OFFSET+21))\n",
    "right_hand_landmarks = list(range(RIGHT_HAND_OFFSET, RIGHT_HAND_OFFSET+21))\n",
    "\n",
    "#generating list with all landmarks selected for preprocessing\n",
    "point_landmarks = [item for sublist in [pose_landmarks, lip_landmarks, left_hand_landmarks, right_hand_landmarks] for item in sublist]\n",
    "\n",
    "#calculating sum of total landmarks used\n",
    "LANDMARKS = len(point_landmarks) + len(averaging_sets)\n",
    "print(LANDMARKS)\n",
    "\n",
    "#defining input shape for model\n",
    "if DROP_Z:\n",
    "    INPUT_SHAPE = (LENGTH,LANDMARKS*2)\n",
    "else:\n",
    "    INPUT_SHAPE = (LENGTH,LANDMARKS*3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    #defines which columns will be read from the file\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    #calculates the number of frames in the data by dividing the length of the data by the number of rows per frame\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    #reshapes the data into a 3D array with shape (n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnecessary function for now; if we want to define handedness of user\n",
    "def right_hand_percentage(x):\n",
    "    #calculates percentage of right hand usage\n",
    "    right = tf.gather(x, right_hand_landmarks, axis=1)\n",
    "    left = tf.gather(x, left_hand_landmarks, axis=1)\n",
    "    right_count = tf.reduce_sum(tf.where(tf.math.is_nan(right), tf.zeros_like(right), tf.ones_like(right)))\n",
    "    left_count = tf.reduce_sum(tf.where(tf.math.is_nan(left), tf.zeros_like(left), tf.ones_like(left)))\n",
    "    return right_count / (left_count+right_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_nan_mean(x, axis=0):\n",
    "    #calculates the mean of a TensorFlow tensor x along a specified axis while ignoring any NaN values in the tensor.\n",
    "    return tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), x), axis=axis) / tf.reduce_sum(tf.where(tf.math.is_nan(x), tf.zeros_like(x), tf.ones_like(x)), axis=axis)\n",
    "\n",
    "def tf_nan_std(x, axis=0):\n",
    "    #calculates the standard deviation of a tensor x along a specified axis, while ignoring any NaN values in the tensor\n",
    "    d = x - tf_nan_mean(x, axis=axis)\n",
    "    return tf.math.sqrt(tf_nan_mean(d * d, axis=axis))\n",
    "\n",
    "#this function is only required if mean and std will be calculated for specific segments of the data\n",
    "def flatten_means_and_stds(x, axis=0):\n",
    "    #Get means and stds\n",
    "    x_mean = tf_nan_mean(x, axis=0)\n",
    "    x_std  = tf_nan_std(x,  axis=0)\n",
    "    #concats mean and std values for each sequence\n",
    "    x_out = tf.concat([x_mean, x_std], axis=0)\n",
    "    x_out = tf.reshape(x_out, (1, INPUT_SHAPE[1]*2))\n",
    "    #replaces NaN values with zeros\n",
    "    x_out = tf.where(tf.math.is_finite(x_out), x_out, tf.zeros_like(x_out))\n",
    "    return x_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Feature Preprocessing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating preprocessing layer that will be added to final model\n",
    "class FeatureGen(tf.keras.layers.Layer):\n",
    "    #defines custom tensorflow layer \n",
    "    def __init__(self):\n",
    "        #initializes layer\n",
    "        super(FeatureGen, self).__init__()\n",
    "    \n",
    "    def call(self, x_in):\n",
    "        #drop z coordinates if required\n",
    "        if DROP_Z:\n",
    "            x_in = x_in[:, :, 0:2]\n",
    "        \n",
    "        #generates list with mean values for landmarks that will be merged\n",
    "        x_list = [tf.expand_dims(tf_nan_mean(x_in[:, av_set[0]:av_set[0]+av_set[1], :], axis=1), axis=1) for av_set in averaging_sets]\n",
    "        #extracts specific columns from input x_in defined by landmarks\n",
    "        x_list.append(tf.gather(x_in, point_landmarks, axis=1))\n",
    "        #concatenates the two tensors from above along axis 1/columns\n",
    "        x = tf.concat(x_list, 1)\n",
    "\n",
    "        #padding to desired length of sequence (defined by LENGTH)\n",
    "        #get current number of rows\n",
    "        x_padded = x\n",
    "        current_rows = tf.shape(x_padded)[0]\n",
    "        #if current number of rows is greater than desired number of rows, truncate excess rows\n",
    "        if current_rows > LENGTH:\n",
    "            x_padded = x_padded[:LENGTH, :, :]\n",
    "        #if current number of rows is less than desired number of rows, add padding\n",
    "        elif current_rows < LENGTH:\n",
    "            #calculate amount of padding needed\n",
    "            pad_rows = LENGTH - current_rows\n",
    "            #specify amount of padding to be added to each dimension\n",
    "            if pad_rows %2 == 0: #if pad_rows is even\n",
    "                paddings = [[pad_rows//2, pad_rows//2], [0, 0], [0, 0]]\n",
    "            else: #if pad_rows is odd\n",
    "                paddings = [[pad_rows//2+1, pad_rows//2], [0, 0], [0, 0]]  \n",
    "            # mode constant: zeros are added\n",
    "            #TODO: change mode so first and last frame are copied?\n",
    "            x_padded = tf.pad(x_padded, paddings, mode='CONSTANT', constant_values=0)\n",
    "        x = x_padded\n",
    "        \n",
    "        #reshape data to 2D or 3D array\n",
    "        if FLATTEN:\n",
    "            x = tf.reshape(x, (1, INPUT_SHAPE[0]*INPUT_SHAPE[1]))\n",
    "        else:\n",
    "            x = tf.reshape(x, (1, INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "        \n",
    "        #replaces NaN values with zero\n",
    "        x = tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#define converter using generated layer\n",
    "feature_converter = FeatureGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(1, 30, 212), dtype=tf.float32, name=None), name='feature_gen_28/SelectV2_2:0', description=\"created by layer 'feature_gen_28'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 30, 212), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tests for generated layer\n",
    "#One tests symbolic tensor, the other tests real data.\n",
    "print(feature_converter(tf.keras.Input((543, 3), dtype=tf.float32, name=\"inputs\")))\n",
    "\n",
    "#file path for kaggle\n",
    "#feature_converter(load_relevant_data_subset(f'/kaggle/input/asl-signs/{pd.read_csv(TRAIN_FILE).path[1]}'))\n",
    "\n",
    "#file path for local notebook\n",
    "#tests preprocessing layer with parquet file\n",
    "feature_converter(load_relevant_data_subset(f'../data/asl-signs/{pd.read_csv(TRAIN_FILE).path[1]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94477/94477 [06:12<00:00, 253.39it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_row(row, right_handed=True):\n",
    "    #for kaggle\n",
    "    #x = load_relevant_data_subset(os.path.join(\"/kaggle/input/asl-signs\", row[1].path))\n",
    "\n",
    "    #for local notebook\n",
    "    #loads data from parquet file\n",
    "    x = load_relevant_data_subset(os.path.join(\"../data/asl-signs\", row[1].path))\n",
    "\n",
    "    #applies preprocessing layer to loaded data\n",
    "    x = feature_converter(tf.convert_to_tensor(x)).cpu().numpy()\n",
    "    #returns transformed x data and label of sign\n",
    "    return x, row[1].label\n",
    "\n",
    "#unnecessary information?! might be useful for later feature engineering\n",
    "right_handed_signer = [26734, 28656, 25571, 62590, 29302, \n",
    "                       49445, 53618, 18796,  4718,  2044, \n",
    "                       37779, 30680]\n",
    "left_handed_signer  = [16069, 32319, 36257, 22343, 27610, \n",
    "                       61333, 34503, 55372, ]\n",
    "both_hands_signer   = [37055, ]\n",
    "messy = [29302, ]\n",
    "\n",
    "def convert_and_save_data():\n",
    "    #reads csv file\n",
    "    df = pd.read_csv(TRAIN_FILE)\n",
    "    #maps label number to sign column\n",
    "    df['label'] = df['sign'].map(label_map)\n",
    "    #sets number of total rows\n",
    "    total = df.shape[0]\n",
    "    #limits number of rows if quick_test is activated\n",
    "    if QUICK_TEST:\n",
    "        total = QUICK_LIMIT\n",
    "    \n",
    "    #generates numpy array with zeros in shape (total number of rows, number of expected columns)\n",
    "    if FLATTEN:\n",
    "        npdata = np.zeros((total, INPUT_SHAPE[0]*INPUT_SHAPE[1]))\n",
    "    else:\n",
    "        npdata = np.zeros((total, INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "    nplabels = np.zeros(total)\n",
    "\n",
    "    #for loop iterates through each row in df dataframe; i is index of the row and row accesses information in the row of df\n",
    "    #tqdm is used for showing progress bar\n",
    "    for i, row in tqdm(enumerate(df.iterrows()), total=total):\n",
    "        #load specific parquet file, run preprocessing layer and save x and y data\n",
    "        (x,y) = convert_row(row)\n",
    "        #save x and y to specific row in prepared numpy arrays\n",
    "        npdata[i,:] = x\n",
    "        nplabels[i] = y\n",
    "        #break if quick test is activated\n",
    "        if QUICK_TEST and i == QUICK_LIMIT - 1:\n",
    "            break\n",
    "        \n",
    "    #save as np file\n",
    "    np.save(\"../data/feature_data.npy\", npdata)\n",
    "    np.save(\"../data/feature_labels.npy\", nplabels)\n",
    "        \n",
    "convert_and_save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94477, 30, 212) (94477,)\n"
     ]
    }
   ],
   "source": [
    "#test of loading data\n",
    "X = np.load(\"../data/feature_data.npy\")\n",
    "y = np.load(\"../data/feature_labels.npy\")\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
